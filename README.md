# Structure

### Dataset Folder

The Dataset folder contains hand-annotated datasets used as input for the models. Each subfolder represents gestures from three different cultures and includes a labels.txt file containing annotated labels for each image.

### Model Evaluation Folder

The Model Evaluation folder includes analysis conducted on the output of the models. It contains:

- **comparison.py**: Generates plots comparing accuracy and BERT scores across three models.
- **plots folder**: Contains plots comparing the results of all models.

### Subfolders (Llava_Evaluation, Perplexity_Evaluation, and BLIP2_Evaluation)

Each subfolder includes:

- **Txt files**: Output of corresponding models with columns "meaning_score" and "gesture_score," evaluated by human annotators.
- **compute_metrics.py**: Computes the number of correct predictions based on human evaluations and calculates BERT scores between assigned and predicted labels.
- **most_common.py**: Computes the most common n-grams in result columns.
- **culture_score_summary.csv**: Scores by culture generated by compute_metrics.py.
- **bert_score_summary.csv**: BERT scores generated by compute_metrics.py.
- **common_phrases_blip2_by_culture.csv**: Common phrases by culture generated by most_common.py.

### Run_Models Folder

The Run_Models folder contains three subfolders, each with scripts used to run corresponding models. 


**Note:**  
Paths in all scripts must be manually set to the appropriate folders.
